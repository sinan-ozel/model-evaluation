services:

  llm:
    image: sinanozel/ollama.0.12.2:llava-7b
    ports:
      - "11434:11434"
    networks:
      - nutrition-information-extraction-evaluation
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: ["gpu"]
            count: all

  embedding:
    image: sinanozel/ollama.0.12.2:all-minilm-33m
    networks:
      - nutrition-information-extraction-evaluation

  evaluator:
    build:
      context: ..
      dockerfile: Dockerfile
    environment:
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - HF_API_KEY=${HF_API_KEY}
    depends_on:
      # - llm
      - embedding
    networks:
      - nutrition-information-extraction-evaluation
    tty: true
    volumes:
      - ./tests:/tests
      - ./providers:/providers
      - ./prompts:/prompts
      - ./evaluation:/evaluation
    command: ["pytest", "--disable-warnings", "-vvv", "--full-trace", "-rs", "--maxfail=1"]

networks:
  nutrition-information-extraction-evaluation:
    driver: bridge